{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Label Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[]\n",
    "filename=r'D:\\images_part1'\n",
    "for sub_folder in os.listdir(os.path.join(filename,\"train\")):\n",
    "    classes.append(sub_folder)\n",
    "print(classes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Dataset Sub folders into a single folder and Resize images acording to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "image_size=224\n",
    "for i in classes:\n",
    "    path_train = os.path.join(filename, 'train', i)\n",
    "    for j in tqdm(os.listdir(path_train)):\n",
    "        img = cv2.imread(os.path.join(path_train, j))\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "        \n",
    "    path_test = os.path.join(filename, 'test', i)\n",
    "    for j in tqdm(os.listdir(path_test)):\n",
    "        img = cv2.imread(os.path.join(path_test, j))\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = shuffle(X_train, y_train,random_state=42)\n",
    "lb=LabelEncoder()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=42,stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augementation of training and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=7,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "     )\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_datagen.fit(X_train)\n",
    "test_datagen.fit(X_valid)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of an image in X_train: \", X_train.shape)\n",
    "print (\"Shape of an image in X_test: \", X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Labels(fractured,non_fractured) to integers 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = lb.fit(y_train)\n",
    "y_train = lb.transform(y_train)\n",
    "y_valid = lb.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "X_train = np.array(X_train)\n",
    "y_test = np.array(y_valid)\n",
    "X_test = np.array(X_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train Shape: \", X_train.shape) \n",
    "print(\"X_test Shape: \", X_valid.shape)\n",
    "print(\"y_train Shape: \", y_train.shape) \n",
    "print(\"y_test Shape: \", y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of some training images of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Define a function to display images\n",
    "def show_images(images, labels):\n",
    "    # Create a grid of subplots\n",
    "    fig, axes = plt.subplots(10, 10, figsize=(9, 9))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Convert BGR image to grayscale\n",
    "        gray_image = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
    "        # Display the image in black and white\n",
    "        ax.imshow(gray_image, cmap='gray')\n",
    "        # Set the title as the label\n",
    "        ax.set_title(labels[i])\n",
    "        # Turn off axis labels\n",
    "        ax.axis('off')\n",
    "    # Adjust layout to avoid overlap\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Show a sample of images from val_images along with their labels from val_labels\n",
    "show_images(X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of some Validation set images of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Define a function to display images\n",
    "def show_images(images, labels):\n",
    "    # Create a grid of subplots\n",
    "    fig, axes = plt.subplots(10, 10, figsize=(9, 9))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Convert BGR image to grayscale\n",
    "        gray_image = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
    "        # Display the image in black and white\n",
    "        ax.imshow(gray_image, cmap='gray')\n",
    "        # Set the title as the label\n",
    "        ax.set_title(labels[i])\n",
    "        # Turn off axis labels\n",
    "        ax.axis('off')\n",
    "    # Adjust layout to avoid overlap\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Show a sample of images from val_images along with their labels from val_labels\n",
    "show_images(X_valid ,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Pre-trained VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 224, 224 \n",
    "vgg = vgg16.VGG16(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,layer) in enumerate(vgg.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Extra Layers over the base VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "num_classes =2\n",
    "def lw(bottom_model, num_classes):\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model  = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.55)(top_model)\n",
    "    top_model  = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(1, activation='sigmoid')(top_model)\n",
    "    return top_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Model\n",
    "FC_Head = lw(vgg, num_classes)\n",
    "model = Model(inputs = vgg.input, outputs = FC_Head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Optimizer and model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "opt=Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=15, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "                    epochs=30, \n",
    "                    validation_data=(X_test,y_test),\n",
    "                    #verbose = 1,\n",
    "                    batch_size=15,\n",
    "                    callbacks=early_callbacks\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "probs = model.predict(X_test).ravel()  # Probabilities of positive class\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(y_test, probs)\n",
    "print(\"AUC Score:\", auc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "    # Get the loss values\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Plot the losses with connected lines\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    plt.plot(epochs, train_loss, 'b-', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have the 'history' object from model.fit() method\n",
    "plot_loss(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_test,y_test)\n",
    "\n",
    "# Print the validation accuracy\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming you have trained and saved your model as 'model'\n",
    "model.save('wrist_fracture2.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
